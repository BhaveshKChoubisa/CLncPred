# -*- coding: utf-8 -*-
"""Oneshot_ testing_New_XGboost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ASyW9gcI5HyVc0p5F3vc7HpnAypvwmcf
"""

# Original
!pip install xgboost
!pip install biopython
from Bio import SeqIO
import pandas as pd
import xgboost as xgb
import pickle
from collections import Counter
from google.colab import files  # For downloading CSV


# ------------------- USER INPUT SELECTION -------------------

print("Select Input Type:")
print("1. Paste multiple sequences (Each sequence on a new line with an ID)")
print("2. Upload a FASTA file")
choice = input("Enter your choice (1 or 2): ").strip()

sequences = []

if choice == "1":
    input_type = "paste"
    print("\n🔹 Enter sequences in the format: ID_NAME SEQUENCE (one per line). Press Enter twice when done:")

    while True:
        line = input().strip()
        if line == "":
            break

        parts = line.split(maxsplit=1)
        if len(parts) != 2:
            print("❌ Invalid format! Use: ID_NAME SEQUENCE")
            continue

        sequences.append((parts[0], parts[1].upper()))

elif choice == "2":
    input_type = "fasta"
    print("\n🔹 Please upload your FASTA file.")
    uploaded = files.upload()
    input_fasta = list(uploaded.keys())[0]
else:
    print("❌ Invalid input! Please enter 1 or 2.")
    exit()

# ------------------- SEQUENCE PROCESSING FUNCTIONS -------------------

def clean_sequence(sequence):
    return ''.join([base if base in 'AGCT' else '' for base in sequence.replace('U', 'T')])

def calculate_tetramers(seq):
    tetramer_counts = Counter(seq[i:i+4] for i in range(len(seq) - 3))
    total_tetramers = sum(tetramer_counts.values())
    return {tetramer: count / total_tetramers for tetramer, count in tetramer_counts.items()} if total_tetramers else {}

def calculate_codons(seq):
    codon_counts = Counter(seq[i:i+3] for i in range(0, len(seq) - 2, 3) if len(seq[i:i+3]) == 3)
    total_codons = sum(codon_counts.values())
    return {codon: count / total_codons for codon, count in codon_counts.items()} if total_codons else {}

def find_orfs(seq):
    start_codon = "ATG"
    stop_codons = {"TAA", "TAG", "TGA"}
    orf_lengths = []
    for frame in range(3):
        start_positions = []
        for i in range(frame, len(seq), 3):
            codon = seq[i:i+3]
            if codon == start_codon:
                start_positions.append(i)
            elif codon in stop_codons:
                while start_positions:
                    start = start_positions.pop(0)
                    orf_lengths.append(i - start + 3)
    return orf_lengths

def calculate_orf_features(seq):
    orf_lengths = find_orfs(seq)
    return (max(orf_lengths) if orf_lengths else 0, sum(orf_lengths) / len(seq) * 100 if orf_lengths else 0)

# ------------------- FEATURE EXTRACTION -------------------

valid_tetramers = [a + b + c + d for a in 'ATCG' for b in 'ATCG' for c in 'ATCG' for d in 'ATCG']
valid_codons = [a + b + c for a in 'ATCG' for b in 'ATCG' for c in 'ATCG']
features_list = []

if input_type == "paste":
    for id_name, seq in sequences:
        seq = clean_sequence(seq)
        if not seq:
            print(f"❌ Invalid sequence for {id_name}!")
            continue
        longest_orf, orf_coverage = calculate_orf_features(seq)
        tetramers = calculate_tetramers(seq)
        codons = calculate_codons(seq)
        feature_values = {
            'ID_Name': id_name,
            'GC Content (%)': (seq.count('G') + seq.count('C')) / len(seq) * 100,
            'Longest ORF': longest_orf,
            'ORF Coverage (%)': orf_coverage,
            'Sequence Length': len(seq)
        }
        feature_values.update({tetramer: tetramers.get(tetramer, 0) for tetramer in valid_tetramers})
        feature_values.update({codon: codons.get(codon, 0) for codon in valid_codons})
        features_list.append(feature_values)

elif input_type == "fasta":
    for record in SeqIO.parse(input_fasta, "fasta"):
        seq = clean_sequence(str(record.seq))
        if not seq:
            continue
        longest_orf, orf_coverage = calculate_orf_features(seq)
        tetramers = calculate_tetramers(seq)
        codons = calculate_codons(seq)
        feature_values = {
            'ID_Name': record.id,
            'GC Content (%)': (seq.count('G') + seq.count('C')) / len(seq) * 100,
            'Longest ORF': longest_orf,
            'ORF Coverage (%)': orf_coverage,
            'Sequence Length': len(seq)
        }
        feature_values.update({tetramer: tetramers.get(tetramer, 0) for tetramer in valid_tetramers})
        feature_values.update({codon: codons.get(codon, 0) for codon in valid_codons})
        features_list.append(feature_values)

# Convert to DataFrame
df = pd.DataFrame(features_list).fillna(0)
df.insert(0, 'ID', range(len(df)))

# ------------------- MODEL LOADING & PREDICTION -------------------

model_path = "/content/best_xgb_model.sav"
loaded_model = pickle.load(open(model_path, 'rb'))
feature_columns = df.columns.difference(['ID', 'ID_Name'], sort=False)
X_test = df[feature_columns]

dmatrix_test = xgb.DMatrix(X_test)
probabilities = loaded_model.predict(dmatrix_test)
prob_class_1 = probabilities if len(probabilities.shape) == 1 else probabilities[:, 1]
predictions = ['LncRNA' if prob > 0.5 else 'CRNA' for prob in prob_class_1]

output_df = pd.DataFrame({
    'ID_Name': df['ID_Name'],
    'Predicted_Probability': prob_class_1,
    'Predicted_Class': predictions
})

# ------------------- DISPLAY OR DOWNLOAD -------------------

if input_type == "paste":
    print("\n🔹 **Prediction Results:**")
    print(output_df[['ID_Name', 'Predicted_Class', 'Predicted_Probability']])
else:
    output_csv = "/content/Output.csv"
    output_df.to_csv(output_csv, index=False)
    files.download(output_csv)
    print(f"\n✅ Predictions saved to {output_csv} and downloaded automatically.")